The core components of Killerbeez can be split into two logical categories:
those which are related to orchestration, and those related to feeding data
to the target\footnote{The program under test is referred to a the ``target''}
program and collecting results.  The former refers to decisions such as what
inputs to use as seed data,\footnote{The initial inputs which will be modified
are referred to as ``seeds''} which mutation algorithms to use, how to minimize
the input corpus and other decisions which are best left to a central
controller.  The latter category contains actions such as launching the
application, tracking code coverage, determining when the target application is
done processing the input and whether the target application crashed, froze due
to something like an infinite loop, or executed new portions of code.

\subsection{Orchestration}
There is a manager that runs on a central server which handles all of the
orchestration tasks.  It decides what mutators will be used on each target
application, handles minimizing interesting inputs, determines if crashes
and hangs are unique, and which inputs can be dropped because the code they
reach is already covered by other inputs. A \BOINC{} server is used to transmit
the work to worker nodes and receive results.

\end{multicols}
\begin{figure}[hp]
\centering
\includegraphics[width=6in]{KILLERBEEZ_Server_Architecture.png}
\caption{Killerbeez Server Architecture}
\label{fig:Killerbeez-server}
\end{figure}
\begin{multicols}{2}

\subsubsection{Manager} \label{Manager Overview}
The manager is what glues together all the server side components.  It is
primarily a bookkeeper to track which targets are available for fuzzing,
the jobs need to be served out to, process the results which come back to
determine if code paths are unique, and interface with external components.

Because the manager is not responsible for running the target application, it
does not need to run on any specific platform.  It can happily run on Linux and
serve out work to be executed by Windows or macOS machines and collect the
results.

The manager is also what will enable future enhancements to be made such as
using a test case generator to produce seed data, which could be used with the
``nop'' mutator, which does not modify the data. Another integration which is
planned is to use Driller\cite{driller} to generate program inputs which reach
code which have not yet been reached by mutation. These integrations are made
possible by providing a REST API to the manager component, which allows things
such as managing seed data or adding more fuzzing targets. The corpus
minimization can also be dealt with via this interface, so it does not have to
be coupled with the internals of the manager, but instead can be run as a
standalone process.

The manager can decide how long each job takes by specifying things like the
number of iterations, so it should be able to scale up to a very large number
of clients.  However, if the manager is ever found to be a bottleneck, multiple
managers servers could be set up and the REST interface used to share
information between them.

% TODO: create a diagram showing how other components can be added on
%       to the system, such as Driller, Synfuzz, and so on

Killerbeez also introduces the idea of obtaining detailed information about
execution for each input which has a unique code path.  This is typically
not done by fuzzers, as obtaining a full trace is much more overhead than
the lightweight instrumentation that \AFL{} or Honggfuzz use. When doing the
typical fuzzing, Killerbeez will typically use lightweight methods of tracking
execution. However, having a full trace is still useful when determining which
seeds to keep or which ones should be weighted more heavily. This concept has
been encapsulated in a Tracer. A tracer is just a special mode of an
instrumentation module, which does not have to be supported. Each time an input
is found which hits a new code path, a tracer job can be added via the manager.
This will be handled via some \BOINC{} client, just like any other fuzzing job.
The results will include full trace data, which will be stored in the manager's
database.  More information about the trace can be found in section
\ref{Tracer}.

\subsubsection{Preparation}  \label{Preparation Overview}
There is also a phase of fuzzing workflows which is often overlooked or
dismissed, which is setting up the target application and deciding specific
fuzzing parameters. This occurs before any real fuzzing begins and includes
things such as compiling the software, possibly with a specific compiler or
compiler flags, determining what options should be enabled in the target
application, decided which portions of the code should be tracked for code
coverage, and how to deal with non-deterministic code.

The compilation requirements are driven by the type of instrumentation chosen,
which has typically just a matter of choosing the option with the lowest
performance penalty. What options to enable is application specific and
subjective.  It depends on the higher level goals.  If the goal is to find a
vulnerability with wide applicability, chose default options. If it is to test
out a specific feature, disable everything except that option. If it's to just
find any bug in any configuration, enable everything.  While these are
important questions, the most interesting step is what to track in terms of
code coverage, and how to deal with non-deterministic code.

The solution \AFL{} uses is to only instrument the main binary, not any of the
libraries. To make sure all code is covered, compiling everything into one
large static executable is recommended. This means tracking execution on code
which doesn't process any user input, and not tracking important code if you
are not able to get the code to compile statically. Killerbeez includes a tool
called the ``Picker'' which automatically determines which libraries should be
instrumented.  The algorithm for doing so is described in section \ref{Picker}.

One important detail is that the picker can not operate effectively when the
target does not have deterministic execution.  If feeding the same file into
the application multiple times results in different code being executed, this
is a problem not only for the Picker, but also for code coverage in general.
\AFL{} does not deal with this problem directly, but it does alert the user to
the fact that the target is non-deterministic. The user can then do things like
hijack calls to functions such as srand() which intentionally introduce
randomness. This is often done for applications which employ cryptography for
initialization vectors and nonces. Under command line Linux applications, this
works fairly well.  On GUI applications in Windows, it does not work as well.
There are system calls in Windows which just fail for no apparent reason. This
is not a problem as the application should be checking the return code to
detect this and handle it appropriately.  However, when this happens it has the
side effect of making the fuzzer think an input was interesting when it was
not.  The details of how non-determinism is handled is also described in
section \ref{Picker}.

\subsection{Execution}
Execution is handled by the fuzzer program, which is aptly named ``fuzzer.''
This can be run manually from the command line, however it is typically run by
the manager, via a \BOINC{} client.  In either case, the fuzzer is responsible
for running the target program, feeding the program data, tracking code
coverage, detecting crashes, and can deal with user interaction such as dialog
boxes.

\end{multicols}
\begin{figure}[hp]
\centering
\includegraphics[width=6in]{killerbeez-high-level-block-diagrams.png}
\caption{Killerbeez Fuzzer Overview}
\label{fig:Killerbeez-fuzzer-overview}
\end{figure}
\begin{multicols}{2}

The fuzzer is really just a bunch of glue code which pulls together various
modules, which are where all the interesting things occur. The purpose of
the Driver, Mutator and Instrumentation modules are covered in sections
\ref{Driver Overview}, \ref{Mutator Overview}, and
\ref{Instrumentation Overview}, respectively.  The modules which currently
exist and how they work are covered in the ``\nameref{Implementation}''
section.

The same code base is used on Windows, Linux and macOS to enable as much code
re-use as possible.  Most of the mutators are shared among all platforms.
Some of the instrumentation and driver\footnote{Unless otherwise noted,
the term ``driver'' refers to driver modules, not operating system drivers}
modules contain platform specific and sometimes the application specific code.

\subsubsection{Driver} \label{Driver Overview}
Killerbeez offers drivers, which are target-specific wrappers that abstract
away the concept of loading data into a target program and enable finer
definition of what failure modes of a particular program look like. While
typical fuzzers look for crashes and hangs, specifically-written drivers can
have more context about a given fuzz target.  Better understanding of the fuzz
target's behavior means that Killerbeez can make better-informed decisions
about the status of a program after a particular input, and it can terminate or
classify the result of a particular input more quickly than waiting for a
timeout.

First, the driver module is responsible for feeding inputs to a program.  This
is a departure from most fuzzers, which only work for one type of input.  In
the case of AFL, the input is a file or stdin (which is also a file under
UNIX).  Syzkaller\cite{syzkaller}, on the other hand, uses only system calls.
Each tool then has to implement their own mutation algorithms, code coverage,
results collection and so forth. Drivers enable Killerbeez to reuse all of
these components and select how to interact with the target by simply selecting
the appropriate driver.  Abstracting this away allows for more exotic use
cases, such as fuzzing IOCTLs, network servers, network clients, \IPC{} such as
Mach Messages, XPC, Distributed Objects, or COM, and others, all with minimal
effort.

The second thing drivers are responsible for is dealing with any application
specific issues, such as handling GUI interactions.  For example, if a PDF file
with a malformed header is given to a PDF reader application, it typically will
pop up a dialog box indicating that the file is corrupt. Fuzzers such as
Honggfuzz or WinAFL would wait until the timeout period.\footnote{WinAFL can
exit at the end of a function, but dialog boxes tend to prevent that function
from returning in practice} This results in all executions which hit this code
path to appear as a hung process.  In Killerbeez, a driver could be written for
the specific PDF reader which monitors the application for dialog boxes,
detects when dialog boxes appear, analyze the text of the dialog box and
determine that the status is a clean exit rather than a hang.  This would allow
the fuzzer to move on to the next input more quickly, as it would know the
input is done being processed and would not need to wait the full timeout
period.  It also helps discern between hangs, which may indicate a Denial of
Service vulnerability such as an infinite loop, and an error which is handled
in the expected manner. For another example, see the Windows Media Player
driver in section \ref{Driver}.

Many of the drivers will work on many fuzzing targets in a particular category.
Targets which accept input from the network, are handled by the Network Server
driver module, programs which open a file are generally handled by the file
driver and so forth.  Other driver can be written to handle things which are
specific to one particular application.  Some targets will handle opening files
differently if opened via double clicking an icon as compared to using the open
option from the file menu. Other examples include error message analysis to
determine if the system should move on to the next input, or if it should click
``OK'' and continue (e.g. in the event of a warning message).

\subsubsection{Mutator} \label{Mutator Overview}
Killerbeez also implements ``mutators,'' which are abstractions on modifying
program's input. They decide where to modify bytes in the input file, and how
to modify them.

Killerbeez uses a selection of user-selectable mutators. Parameters are passed
to the mutator module via the driver, which control the operation of the
mutator. For example, the bit flip mutator flips a parametrized number of bits
throughout the entire input, one at a time.

Modular mutators also enable trivial combination of different approaches. Using
the multipart mutator, different mutators can be applied to different parts of
the input. This is required for efficiently fuzzing network protocols, as it is
often desirable to not mutate the initial packets as they may be a handshake or
authentication and any mutation would prevent interesting code from being
executed, as the target program would go down an error path instead. It can
also be used to ensure that the first few bytes in a file are not modified so
the file will still be recognized as being the correct file type.


\subsubsection{Instrumentation} \label{Instrumentation Overview}
Instrumentation modules are responsible for tracking program execution and
determining if new code has been executed by the input data. How it does this,
and what level of granularity is used, are questions left to the module author.
There is an \IPT{} instrumentation module which is very high resolution, which
means if a loop somewhere in the target is executed 178 times instead of 177
times, it will detect this as a new code path, as the state explored is
different than what was seen before.  The \AFL{} instrumentation module, on the
other hand, would not consider this to be an input which covers new code. This
is due to the bucketing system \AFL{} uses which groups executions of the same
code and considers anything which executes a portion of code 128-255 times to
be equivalent.

Sometimes instrumentation involves dealing with specific drivers, which are
implemented differently on different operating systems. The \IPT{}
instrumentation module uses the perf subsystem on Linux, which is not available
on macOS or Windows. Other instrumentation technologies, such as Intel's
Pin\cite{pin}, have a very similar interface across different operating
systems, which means more of the code in the instrumentation module can be
re-used, simply using \#ifdef directives if there are portions which are
specific to a particular operating system.
